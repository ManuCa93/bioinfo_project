head(100) # Prendiamo i top 100
cat("Top 10 New Candidates identified by Network Propagation:\n")
kable(head(new_candidates[, c("Symbol", "Score")], 10))
library(gprofiler2)
# Eseguiamo l'enrichment
gostres <- gost(query = new_candidates$Symbol,
organism = "hsapiens",
ordered_query = TRUE,
significant = TRUE,
sources = c("GO:BP", "KEGG", "REAC"))
if (!is.null(gostres$result)) {
# 1. Manhattan Plot (Visualizzazione Grafica)
p <- gostplot(gostres, capped = FALSE, interactive = FALSE)
print(p)
# 2. Tabella dei Top Pathway
top_pathways <- gostres$result %>%
select(source, term_name, p_value, intersection_size) %>%
arrange(p_value) %>%
head(15)
kable(top_pathways, caption = "Top Enriched Pathways for Predicted Genes")
} else {
cat("No significant enrichment found (likely due to random simulated data).\n")
}
library(ggplot2)
library(knitr)
library(dplyr)
# 1. Calcolo del grado (numero di connessioni per ogni nodo)
node_degrees <- degree(giant_component)
deg_df <- data.frame(GeneID = names(node_degrees), Degree = node_degrees)
# 2. Grafico Distribuzione Gradi (Scala Log-Log)
# Questo replica il grafico "Degree Distribution" del notebook Python
ggplot(deg_df, aes(x = Degree)) +
geom_histogram(bins = 50, fill = "darkblue", color = "white", alpha=0.8) +
scale_y_log10() +
scale_x_log10() +
labs(title = "Degree Distribution (Log-Log Scale)",
subtitle = "Network Topology Analysis",
x = "Degree (k)", y = "Frequency P(k)") +
theme_minimal()
# 3. Identificazione dei Top 15 Hubs
# Uniamo con la tabella NCBI per avere i nomi (Symbol) e le descrizioni
top_hubs <- deg_df %>%
arrange(desc(Degree)) %>%
head(15) %>%
left_join(genes_ncbi, by = "GeneID") %>%
select(Symbol, Degree, description)
kable(top_hubs, caption = "Top 15 Hub Genes identified in the Network")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# install recount3
if (!requireNamespace("BiocManager", quietly = TRUE)) {
install.packages("BiocManager")
}
if (!requireNamespace("recount3", quietly = TRUE)) {
BiocManager::install("recount3")
}
library(recount3)
library(SummarizedExperiment)
# 1) List of available projects in recount3
projects <- available_projects()
# 2) we want TCGA (The Cancer Genome Atlas)
tcga_projects <- subset(projects, file_source == "tcga")
# 3) select LUAD (Lung Adenocarcinoma)
projinfo_luad <- subset(tcga_projects, project == "LUAD")
projinfo_luad
# 4) Download the SummarisedExperiment object with the counts (genes x samples)
rse_gene <- create_rse(projinfo_luad)
# 5) Extract sample count matrix and metadata
counts  <- assay(rse_gene, "raw_counts")   # raw count matrix
coldata <- colData(rse_gene)           # metadata (info on samples)
dim(counts)              # n genes x n samples
colnames(counts)[1:5]
# 6) 2 tipy of smaples: Primary Tumor vs Solid Tissue Normal
sample_type <- coldata$tcga.gdc_cases.samples.sample_type
table(sample_type)
# 7) filter for only tumor and not tumor
keep <- sample_type %in% c("Primary Tumor", "Solid Tissue Normal")
rse_gene_sub <- rse_gene[, keep]
counts_sub  <- assay(rse_gene_sub, "raw_counts")
coldata_sub <- as.data.frame(colData(rse_gene_sub))
dim(counts_sub)
table(coldata_sub$tcga.gdc_cases.samples.sample_type)
# 8) Variable 'condition' = normal / tumor
condition <- ifelse(
coldata_sub$tcga.gdc_cases.samples.sample_type == "Primary Tumor",
"tumor",
"normal"
)
coldata_sub$condition <- factor(condition, levels = c("normal", "tumor"))
# Final check
table(coldata_sub$condition)
library(tidyverse)
# --- FILE IN LOCAL ---
possible_paths <- c("data/HIPPIE-current.mitab.txt", "HIPPIE-current.mitab.txt")
found_path <- NULL
for (path in possible_paths) {
if (file.exists(path)) {
found_path <- path
break
}
}
if (is.null(found_path)) {
stop("
======================================================================
ERRORE: FILE 'HIPPIE-current.mitab.txt' NON TROVATO.
Hai detto di averlo scaricato. Per favore:
1. Controlla dove l'hai salvato.
2. Spostalo nella stessa cartella di questo file .Rmd (o nella sottocartella 'data').
3. Assicurati che il nome sia ESATTAMENTE: HIPPIE-current.mitab.txt
4. Riprova a premere Knit.
======================================================================
")
} else {
message(paste("File found in:", found_path))
}
hippie_cols <- c(
"ID_Interactor_A", "ID_Interactor_B", "Alt_IDs_Interactor_A", "Alt_IDs_Interactor_B",
"Aliases_Interactor_A", "Aliases_Interactor_B", "Interaction_Detection_Methods",
"Publication_1st_Author", "Publication_Identifiers", "Taxid_Interactor_A", "Taxid_Interactor_B",
"Interaction_Types", "Source_Databases", "Interaction_Identifiers", "Confidence_Value",
"Presence_In_Other_Species", "Gene_Name_Interactor_A", "Gene_Name_Interactor_B"
)
# Loading of data
hippie <- read_tsv(found_path, col_names = hippie_cols, comment = "#", show_col_types = FALSE)
# only confidence >= 0.65
edges_clean <- hippie %>%
filter(Confidence_Value >= 0.65) %>%
mutate(
ID_Interactor_A = str_remove(ID_Interactor_A, "entrez gene:"),
ID_Interactor_B = str_remove(ID_Interactor_B, "entrez gene:")
) %>%
select(ID_Interactor_A, ID_Interactor_B, Confidence_Value)
cat("Interactions loaded (Score >= 0.65):", format(nrow(edges_clean), big.mark=","), "\n")
library(tidyverse)
# FILE LOCALI NCBI
# Cerchiamo il file NCBI
ncbi_filename <- "Homo_sapiens.gene_info.gz"
possible_ncbi_paths <- c(paste0("data/", ncbi_filename), ncbi_filename)
found_ncbi_path <- NULL
for (path in possible_ncbi_paths) {
if (file.exists(path)) {
found_ncbi_path <- path
break
}
}
# Only columns that wre need
genes_ncbi <- read_tsv(found_ncbi_path, show_col_types = FALSE) %>%
select(GeneID, Symbol, description) %>%
mutate(GeneID = as.character(GeneID))
# We only keep interactions in the network where both genes are recognised
edges_final <- edges_clean %>%
filter(ID_Interactor_A %in% genes_ncbi$GeneID & ID_Interactor_B %in% genes_ncbi$GeneID)
cat("Final Valid Interactions:", format(nrow(edges_final), big.mark=","), "\n")
library(igraph)
# Graph construction (Network)
# 'edges_final' contains pairs of interacting genes
ppi_net <- graph_from_data_frame(d = edges_final, directed = FALSE)
# add symbols to nodes in the network.
V(ppi_net)$symbol <- genes_ncbi$Symbol[match(V(ppi_net)$name, genes_ncbi$GeneID)]
# remove self-links and duplicates
ppi_net <- simplify(ppi_net, remove.multiple = TRUE, remove.loops = TRUE)
# extraction of Giant Component
comps <- components(ppi_net)
giant_id <- which.max(comps$csize)
giant_component <- induced_subgraph(ppi_net, which(comps$membership == giant_id))
cat("Giant Component Stats:\n")
cat("Nodes:", format(vcount(giant_component), big.mark=","), "\n")
library(ggplot2)
library(knitr)
library(dplyr)
# 1. Calculation of degree (number of connections per node)
node_degrees <- degree(giant_component)
deg_df <- data.frame(GeneID = names(node_degrees), Degree = node_degrees)
# 2. Grade Distribution Chart (Log-Log Scale)
ggplot(deg_df, aes(x = Degree)) +
geom_histogram(bins = 50, fill = "darkblue", color = "white", alpha=0.8) +
scale_y_log10() +
scale_x_log10() +
labs(title = "Degree Distribution (Log-Log Scale)",
subtitle = "Network Topology Analysis",
x = "Degree (k)", y = "Frequency P(k)") +
theme_minimal()
# 3. identification ofi Top 15 Hubs
top_hubs <- deg_df %>%
arrange(desc(Degree)) %>%
head(15) %>%
left_join(genes_ncbi, by = "GeneID") %>%
select(Symbol, Degree, description)
kable(top_hubs, caption = "Top 15 Hub Genes identified in the Network")
library(igraph)
# --- INIZIO SIMULAZIONE (DA CANCELLARE CON I DATI VERI) ---
set.seed(123)
# Simuliamo 50 geni "malati" presi a caso dalla rete
#disease_gene_ids <- sample(V(giant_component)$name, 50)
#message("WARNING: Using SIMULATED disease genes. Replace with real DE genes for final report.")
# --- FINE SIMULAZIONE ---
# --- CODICE DA SCOMMENTARE QUANDO HAI I DATI VERI ---
# 1. load the file CSV
de_results <- read.csv("data/results_de_genes_LUAD.csv")
#
# 2. Filter significant genes (padj < 0.05)
# disease_gene_ids <- as.character(de_results$GeneID[de_results$padj < 0.05])
disease_gene_ids <- as.character(de_results$entrez_id[de_results$padj < 0.05])
#
# 3. Ensure that these genes are present in the network
# disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
# ==============================================================================
# ALGORITHM EXECUTION (Equivalent to random_walker in the Python notebook)
# 85% pro restart
rwr_scores <- page_rank(
giant_component,
directed = FALSE,
damping = 0.85,
personalized = as.numeric(V(giant_component)$name %in% disease_gene_ids)
)$vector
# Creating Results Table
results_df <- data.frame(
GeneID = names(rwr_scores),
Score = rwr_scores,
Symbol = V(giant_component)$symbol
) %>%
arrange(desc(Score))
# We identify NEW candidates
# (High-scoring genes that were NOT on the initial list of diseased genes)
new_candidates <- results_df %>%
filter(!GeneID %in% disease_gene_ids) %>%
head(100) # Prendiamo i top 100
cat("Top 10 New Candidates identified by Network Propagation:\n")
kable(head(new_candidates[, c("Symbol", "Score")], 10))
library(gprofiler2)
# Enrichment
gostres <- gost(query = new_candidates$Symbol,
organism = "hsapiens",
ordered_query = TRUE,
significant = TRUE,
sources = c("GO:BP", "KEGG", "REAC"))
if (!is.null(gostres$result)) {
# 1. Manhattan Plot
p <- gostplot(gostres, capped = FALSE, interactive = FALSE)
print(p)
# 2. Top Pathway
top_pathways <- gostres$result %>%
select(source, term_name, p_value, intersection_size) %>%
arrange(p_value) %>%
head(15)
kable(top_pathways, caption = "Top Enriched Pathways for Predicted Genes")
} else {
cat("No significant enrichment found (likely due to random simulated data).\n")
}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# install recount3
if (!requireNamespace("BiocManager", quietly = TRUE)) {
install.packages("BiocManager")
}
if (!requireNamespace("recount3", quietly = TRUE)) {
BiocManager::install("recount3")
}
library(recount3)
library(SummarizedExperiment)
# 1) List of available projects in recount3
projects <- available_projects()
# 2) we want TCGA (The Cancer Genome Atlas)
tcga_projects <- subset(projects, file_source == "tcga")
# 3) select LUAD (Lung Adenocarcinoma)
projinfo_luad <- subset(tcga_projects, project == "LUAD")
projinfo_luad
# 4) Download the SummarisedExperiment object with the counts (genes x samples)
rse_gene <- create_rse(projinfo_luad)
# 5) Extract sample count matrix and metadata
counts  <- assay(rse_gene, "raw_counts")   # raw count matrix
coldata <- colData(rse_gene)           # metadata (info on samples)
dim(counts)              # n genes x n samples
colnames(counts)[1:5]
# 6) 2 tipy of smaples: Primary Tumor vs Solid Tissue Normal
sample_type <- coldata$tcga.gdc_cases.samples.sample_type
table(sample_type)
# 7) filter for only tumor and not tumor
keep <- sample_type %in% c("Primary Tumor", "Solid Tissue Normal")
rse_gene_sub <- rse_gene[, keep]
counts_sub  <- assay(rse_gene_sub, "raw_counts")
coldata_sub <- as.data.frame(colData(rse_gene_sub))
dim(counts_sub)
table(coldata_sub$tcga.gdc_cases.samples.sample_type)
# 8) Variable 'condition' = normal / tumor
condition <- ifelse(
coldata_sub$tcga.gdc_cases.samples.sample_type == "Primary Tumor",
"tumor",
"normal"
)
coldata_sub$condition <- factor(condition, levels = c("normal", "tumor"))
# Final check
table(coldata_sub$condition)
library(tidyverse)
# --- FILE IN LOCAL ---
possible_paths <- c("data/HIPPIE-current.mitab.txt", "HIPPIE-current.mitab.txt")
found_path <- NULL
for (path in possible_paths) {
if (file.exists(path)) {
found_path <- path
break
}
}
if (is.null(found_path)) {
stop("
======================================================================
ERRORE: FILE 'HIPPIE-current.mitab.txt' NON TROVATO.
Hai detto di averlo scaricato. Per favore:
1. Controlla dove l'hai salvato.
2. Spostalo nella stessa cartella di questo file .Rmd (o nella sottocartella 'data').
3. Assicurati che il nome sia ESATTAMENTE: HIPPIE-current.mitab.txt
4. Riprova a premere Knit.
======================================================================
")
} else {
message(paste("File found in:", found_path))
}
hippie_cols <- c(
"ID_Interactor_A", "ID_Interactor_B", "Alt_IDs_Interactor_A", "Alt_IDs_Interactor_B",
"Aliases_Interactor_A", "Aliases_Interactor_B", "Interaction_Detection_Methods",
"Publication_1st_Author", "Publication_Identifiers", "Taxid_Interactor_A", "Taxid_Interactor_B",
"Interaction_Types", "Source_Databases", "Interaction_Identifiers", "Confidence_Value",
"Presence_In_Other_Species", "Gene_Name_Interactor_A", "Gene_Name_Interactor_B"
)
# Loading of data
hippie <- read_tsv(found_path, col_names = hippie_cols, comment = "#", show_col_types = FALSE)
# only confidence >= 0.65
edges_clean <- hippie %>%
filter(Confidence_Value >= 0.65) %>%
mutate(
ID_Interactor_A = str_remove(ID_Interactor_A, "entrez gene:"),
ID_Interactor_B = str_remove(ID_Interactor_B, "entrez gene:")
) %>%
select(ID_Interactor_A, ID_Interactor_B, Confidence_Value)
cat("Interactions loaded (Score >= 0.65):", format(nrow(edges_clean), big.mark=","), "\n")
library(tidyverse)
# FILE LOCALI NCBI
# Cerchiamo il file NCBI
ncbi_filename <- "Homo_sapiens.gene_info.gz"
possible_ncbi_paths <- c(paste0("data/", ncbi_filename), ncbi_filename)
found_ncbi_path <- NULL
for (path in possible_ncbi_paths) {
if (file.exists(path)) {
found_ncbi_path <- path
break
}
}
# Only columns that wre need
genes_ncbi <- read_tsv(found_ncbi_path, show_col_types = FALSE) %>%
select(GeneID, Symbol, description) %>%
mutate(GeneID = as.character(GeneID))
# We only keep interactions in the network where both genes are recognised
edges_final <- edges_clean %>%
filter(ID_Interactor_A %in% genes_ncbi$GeneID & ID_Interactor_B %in% genes_ncbi$GeneID)
cat("Final Valid Interactions:", format(nrow(edges_final), big.mark=","), "\n")
library(igraph)
# Graph construction (Network)
# 'edges_final' contains pairs of interacting genes
ppi_net <- graph_from_data_frame(d = edges_final, directed = FALSE)
# add symbols to nodes in the network.
V(ppi_net)$symbol <- genes_ncbi$Symbol[match(V(ppi_net)$name, genes_ncbi$GeneID)]
# remove self-links and duplicates
ppi_net <- simplify(ppi_net, remove.multiple = TRUE, remove.loops = TRUE)
# extraction of Giant Component
comps <- components(ppi_net)
giant_id <- which.max(comps$csize)
giant_component <- induced_subgraph(ppi_net, which(comps$membership == giant_id))
cat("Giant Component Stats:\n")
cat("Nodes:", format(vcount(giant_component), big.mark=","), "\n")
library(ggplot2)
library(knitr)
library(dplyr)
# 1. Calculation of degree (number of connections per node)
node_degrees <- degree(giant_component)
deg_df <- data.frame(GeneID = names(node_degrees), Degree = node_degrees)
# 2. Grade Distribution Chart (Log-Log Scale)
ggplot(deg_df, aes(x = Degree)) +
geom_histogram(bins = 50, fill = "darkblue", color = "white", alpha=0.8) +
scale_y_log10() +
scale_x_log10() +
labs(title = "Degree Distribution (Log-Log Scale)",
subtitle = "Network Topology Analysis",
x = "Degree (k)", y = "Frequency P(k)") +
theme_minimal()
# 3. identification ofi Top 15 Hubs
top_hubs <- deg_df %>%
arrange(desc(Degree)) %>%
head(15) %>%
left_join(genes_ncbi, by = "GeneID") %>%
select(Symbol, Degree, description)
kable(top_hubs, caption = "Top 15 Hub Genes identified in the Network")
library(igraph)
# --- INIZIO SIMULAZIONE (DA CANCELLARE CON I DATI VERI) ---
set.seed(123)
# Simuliamo 50 geni "malati" presi a caso dalla rete
#disease_gene_ids <- sample(V(giant_component)$name, 50)
#message("WARNING: Using SIMULATED disease genes. Replace with real DE genes for final report.")
# --- FINE SIMULAZIONE ---
# --- CODICE DA SCOMMENTARE QUANDO HAI I DATI VERI ---
# 1. load the file CSV
de_results <- read.csv("data/results_de_genes_LUAD.csv")
#
# 2. Filter significant genes (padj < 0.05)
# disease_gene_ids <- as.character(de_results$GeneID[de_results$padj < 0.05])
disease_gene_ids <- as.character(de_results$entrez_id[de_results$padj < 0.05])
#
# 3. Ensure that these genes are present in the network
# disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
# ==============================================================================
# ALGORITHM EXECUTION (Equivalent to random_walker in the Python notebook)
# 85% pro restart
rwr_scores <- page_rank(
giant_component,
directed = FALSE,
damping = 0.85,
personalized = as.numeric(V(giant_component)$name %in% disease_gene_ids)
)$vector
# Creating Results Table
results_df <- data.frame(
GeneID = names(rwr_scores),
Score = rwr_scores,
Symbol = V(giant_component)$symbol
) %>%
arrange(desc(Score))
# We identify NEW candidates
# (High-scoring genes that were NOT on the initial list of diseased genes)
new_candidates <- results_df %>%
filter(!GeneID %in% disease_gene_ids) %>%
head(100) # Prendiamo i top 100
cat("Top 10 New Candidates identified by Network Propagation:\n")
kable(head(new_candidates[, c("Symbol", "Score")], 10))
library(gprofiler2)
# Enrichment
gostres <- gost(query = new_candidates$Symbol,
organism = "hsapiens",
ordered_query = TRUE,
significant = TRUE,
sources = c("GO:BP", "KEGG", "REAC"))
if (!is.null(gostres$result)) {
# 1. Manhattan Plot
p <- gostplot(gostres, capped = FALSE, interactive = FALSE)
print(p)
# 2. Top Pathway
top_pathways <- gostres$result %>%
select(source, term_name, p_value, intersection_size) %>%
arrange(p_value) %>%
head(15)
kable(top_pathways, caption = "Top Enriched Pathways for Predicted Genes")
} else {
cat("No significant enrichment found (likely due to random simulated data).\n")
}
library(igraph)
# --- INIZIO SIMULAZIONE (DA CANCELLARE CON I DATI VERI) ---
set.seed(123)
# Simuliamo 50 geni "malati" presi a caso dalla rete
#disease_gene_ids <- sample(V(giant_component)$name, 50)
#message("WARNING: Using SIMULATED disease genes. Replace with real DE genes for final report.")
# --- FINE SIMULAZIONE ---
# --- CODICE DA SCOMMENTARE QUANDO HAI I DATI VERI ---
# 1. load the file CSV
de_results <- read.csv("data/results_de_genes_LUAD.csv")
#
# 2. Filter significant genes (padj < 0.05)
# disease_gene_ids <- as.character(de_results$GeneID[de_results$padj < 0.05])
disease_gene_ids <- as.character(de_results$entrez_id[de_results$padj < 0.05])
#
# 3. Ensure that these genes are present in the network
# disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
disease_gene_ids <- intersect(disease_gene_ids, V(giant_component)$name)
# ==============================================================================
# ALGORITHM EXECUTION (Equivalent to random_walker in the Python notebook)
# 85% pro restart
rwr_scores <- page_rank(
giant_component,
directed = FALSE,
damping = 0.85,
personalized = as.numeric(V(giant_component)$name %in% disease_gene_ids)
)$vector
# Creating Results Table
results_df <- data.frame(
GeneID = names(rwr_scores),
Score = rwr_scores,
Symbol = V(giant_component)$symbol
) %>%
arrange(desc(Score))
# We identify NEW candidates
# (High-scoring genes that were NOT on the initial list of diseased genes)
new_candidates <- results_df %>%
filter(!GeneID %in% disease_gene_ids) %>%
head(100) # Prendiamo i top 100
cat("Top 10 New Candidates identified by Network Propagation:\n")
kable(head(new_candidates[, c("Symbol", "Score")], 10))
library(gprofiler2)
# Enrichment
gostres <- gost(query = new_candidates$Symbol,
organism = "hsapiens",
ordered_query = TRUE,
significant = TRUE,
sources = c("GO:BP", "KEGG", "REAC"))
if (!is.null(gostres$result)) {
# 1. Manhattan Plot
p <- gostplot(gostres, capped = FALSE, interactive = FALSE)
print(p)
# 2. Top Pathway
top_pathways <- gostres$result %>%
select(source, term_name, p_value, intersection_size) %>%
arrange(p_value) %>%
head(15)
kable(top_pathways, caption = "Top Enriched Pathways for Predicted Genes")
} else {
cat("No significant enrichment found (likely due to random simulated data).\n")
}
